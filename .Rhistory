library(tidyverse)
mtcars <- as_tibble(mtcars)
mtcars
?mtcars
ggplot(data = mtcars) +
geom_point(mapping = aes(x = mpg, y = disp, alpha = am))
ggplot(data = mtcars) +
geom_point(mapping = aes(x = mpg, y = disp, shape = am))
ggplot(data = mtcars) +
geom_point(mapping = aes(x = mpg, y = disp, shape = as.character(am)))
ggplot(data = mtcars) +
geom_point(mapping = aes(x = mpg, y = disp, size = am))
ggplot(data = mtcars) +
geom_point(mapping = aes(x = mpg, y = disp, colour = am))
mtcars <- as_tibble(cars)
mtcars
mtcars <- as_tibble(mtcars)
mtcars
mtcars
mpg
install.packages("fivethirtyeight")
library(fivethirtyeight)
trump_twitter
college_all_ages
?college_all_ages
college_all_ages
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = median))
college_all_ages$median
college_all_ages
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = employed))
View(college_all_ages)
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = unemployed))
options(scipen = 93421)
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = unemployed))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = median))
View(college_all_ages)
filter(college_all_ages, median > 1000000)
options(scipen = 0)
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = median))
options(scipen = 999)
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = total, y = median))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total))
college_all_ages
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total, colour = unemployment_rate))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total, colour = major))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total, colour = major_category))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total, colour = unemployment_rate))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total, size = major_category))
ggplot(data = college_all_ages) +
geom_point(mapping = aes(x = median, y = total, shape = major_category))
college_all_ages
View(college_all_ages)
library(haven)
library(PISA2000lite)
library(PISA2003lite)
library(PISA2006lite)
library(PISA2009lite)
library(PISA2012lite)
library(intsvy)
library(cimentadaj) # For pisa_countrynames
library(countrycode) # For region variable
library(tidyverse)
library(car)
library(readr)
library(SAScii)
pisa_2015 <- read_spss("/Users/cimentadaj/Downloads/PISA/PISA2015/CY6_MS_CMB_STU_QQQ.sav")
pisa2012_dir <- "/Users/cimentadaj/Downloads/PISA/PISA2012/"
dic_student <- parse.SAScii(sas_ri = paste0(pisa2012_dir, 'PISA2012_SAS_student.sas'))
student2012 <- read_fwf(file = paste0(pisa2012_dir, 'INT_STU12_DEC03.txt'), col_positions = fwf_widths(dic_student$width), progress = T)
colnames(student2012) <- dic_student$varname
student2015 <- pisa_2015 # toy dataset
# student2012 <- cbind(student2012, student2012weights)
# # If PISA2012 starts working, then use this code:
# # Vector with database names except student2015
# databases <- c("math2000", paste0("student", seq(2003, 2012, 3)))
#
# # Create a list with all data sets
# pisa_list <- map(c(databases, "student2015"), get)
#
# # Give each dataset their own name
# names(pisa_list) <- c("student2000", databases[-1], "student2015")
# Provisional code for separate PISA2012
# Vector with database names except student2015
databases <- c("math2000", paste0("student", seq(2003, 2009, 3)))
# Create a list with all data sets
pisa_list <- map(c(databases, paste0("student", c(2012, 2015))), get)
# Give each dataset their own name
names(pisa_list) <- c("student2000", databases[-1], "student2012","student2015")
# Fix the country variable name which is different for PISA 2000
pisa_list$math2000$CNT <- pisa_list$math2000$COUNTRY
# Create a data frame with a list column containing all lists.
pisa_all <- enframe(pisa_list)
# See:
pisa_all
# Go through each PISA and grab the highest education from Male
# and Female partner. Finally, recode it to three categories
pisa_all$value <- map(pisa_all$value, function(each_pisa) {
each_pisa$high_edu <- pmax(as.numeric(each_pisa$MISCED), # find highest education
as.numeric(each_pisa$FISCED)) # in the household
# Recode new highest education into three categories
each_pisa$high_edu <- recode(each_pisa$high_edu, "1:3 = 1; 4:5 = 2; 6:7 = 3; else = NA")
each_pisa
})
# Gender variables:
# 2000: ST03Q01
# 2003: ST03Q01
# 2006: ST04Q01
# 2009: ST04Q01
# 2012: ST04Q01
# 2015: ST004D01T
# Vector with all gender vars in order of PISA surveys
gender <- c("ST03Q01", "ST03Q01", "ST04Q01", "ST04Q01", "ST04Q01", "ST004D01T")
# Loop through each data frame and assign the gender variable name
# and turn it into character
pisa_all$value <- map(seq_along(pisa_all$value), function(pisa_data) {
pisa_all$value[[pisa_data]] %>%
rename_("gender" = gender[pisa_data]) %>%
mutate(gender = as.character(gender),
country = pisa_countrynames[CNT],
region = countrycode(country, "country.name", "region")) %>%
as_tibble()
})
pisa_all2 <- pisa_all
pisa_all2$pv_mean <-
map(seq_len(nrow(pisa_all2)), function(data) {
if (pisa_all2[data, 1] == "student2015") {
pisa2015.mean.pv("MATH", by = c("country", "high_edu"), data = pisa_all2[[data, 2]])
} else {
pisa.mean.pv("MATH", by = c("country", "high_edu"), data = pisa_all2[[data, 2]])
}
})
pisa_all2$quantile_mean <-
map(seq_len(nrow(pisa_all2)), function(data) {
print(data)
if (pisa_all2[data, 1] == "student2015") {
pisa2015.per.pv("MATH", per = c(10, 20, 80, 90), by = c("country"), data = pisa_all2[[data, 2]])
} else {
pisa.per.pv("MATH", per = c(10, 20, 80, 90), by = c("country"), data = pisa_all2[[data, 2]])
}
})
pisa_merged <-
pisa_all2 %>%
separate(name, c("type", "year"), 7)
unnest_rename <- function(df, col_unnest, var_rename) {
unnested <-
df %>%
unnest_(col_unnest)
if(sum(names(unnested) %in% var_rename) > 1) {
warning(paste(as.name(var_rename), "not a unique name in unnested df. Renaming the first instance"))
}
unnested %>%
rename_(se_mean = var_rename)
}
pisa_ci <- function(df, col_unnest, var_rename, mean_var) {
dots <- setNames(list(
lazyeval::interp(~ x - y, x = as.name(mean_var), y = quote(se_twice)),
lazyeval::interp(~ x + y, x = as.name(mean_var), y = quote(se_twice))
), c("low_ci", "upper_ci"))
unnest_rename(pisa_merged, col_unnest, var_rename) %>%
mutate(
se_twice = 2 * se_mean,
region = countrycode(country, "country.name", "region"),
continent = countrycode(country, "country.name", "continent")
) %>%
mutate_(.dots = dots) %>%
filter(!is.na(continent))
}
pisa_quant_ci <-
pisa_ci(pisa_merged, "quantile_mean", "`Std. err.`", "Score")
pisa_pv_ci <-
pisa_ci(pisa_merged, "pv_mean", "s.e.", "Mean")
beepr::beep()
pisa_pv_ci %>%
group_by(year, continent) %>%
summarise(
n = n(),
mean_score = mean(Mean, na.rm = T),
mean_low_ci = mean(low_ci, na.rm = T),
mean_upper_ci = mean(upper_ci, na.rm = T)
) %>%
ggplot(aes(year, mean_score)) +
geom_point() +
geom_pointrange(aes(ymin = mean_low_ci,
ymax = mean_upper_ci,
colour = continent)) +
geom_line(aes(group = continent,
colour = continent))
# Convergence of European countries
pisa_col_diff <- function(df, stacked_var, vals_filter, value_var) {
filter_dots <- lazyeval::interp(~ x %in% y, x = as.name(stacked_var), y = vals_filter)
select_dots <- map(c("year", "country", "region", "continent", stacked_var, value_var), as.name)
mutate_dots <- paste(c(as.name(vals_filter[1]), as.name(vals_filter[2])), collapse = " - ")
df %>%
filter_(.dots = filter_dots) %>%
select_(.dots = select_dots) %>%
spread_(stacked_var, value_var) %>%
mutate_(diff = paste0("abs(", mutate_dots, ")")) %>%
gather_(stacked_var, value_var, c(vals_filter, "diff"))
}
pisa_pv_differenced <-
pisa_col_diff(pisa_pv_ci, "high_edu", c(1, 3), "Mean") %>%
filter(high_edu == "diff")
pisa_quant_differenced <-
pisa_col_diff(pisa_quant_ci, "Percentiles", c(90, 10), "Score") %>%
filter(Percentiles == "diff")
pisa_quant_differenced_eighty <-
pisa_col_diff(pisa_quant_ci, "Percentiles", c(80, 20), "Score") %>%
filter(Percentiles == "diff")
dataset <- c("pisa_pv_differenced", "pisa_quant_differenced", "pisa_quant_differenced_eighty")
filter_vars <- c("high_edu", rep("Percentiles", 2))
vals <- c("Mean", rep("Score", 2))
dir <- normalizePath("./Google Drive/PhD project/PISA/plots/")
map2(dataset, vals, function(data, value) {
get(data) %>%
filter(continent == "Europe") %>%
ggplot(aes_string("year", value)) +
geom_smooth(aes(group = country, colour = country), method = "lm",
se = F) +
ggtitle(data) +
ggsave(paste("plot0_", data), path = dir, device = "png")
})
# Function to do non-standard filtering. In case needed
# dplyr_filter <- function(df, name, what_filter) {
#   df %>%
#     filter_(.dots = lazyeval::interp(~ y == x, y = as.name(name), x = what_filter))
# }
dplyr_mean <- function(df, new_name, x) {
df %>%
summarise_(.dots = setNames(list(lazyeval::interp(~ mean(x, na.rm = T), x  = x)), new_name))
}
# Lower variance for each year
# Lower difference in general
# Estimate by excluding the outliers
# in the model.
map(seq_along(dataset), function(index) {
summarise_dots <- setNames(list(lazyeval::interp(~ sd(x, na.rm = T), x  = as.name(vals[index])),
lazyeval::interp(~ mean(x, na.rm = T), x  = as.name(vals[index]))),
c("var", "mean_diff"))
get(dataset[index]) %>%
group_by(year) %>%
summarise_(.dots = summarise_dots)
}) %>%
setNames(dataset)
# Convergence of continents
map2(dataset, vals, function(data, values) {
get(data) %>%
group_by(year, continent) %>%
dplyr_mean("diff", as.name(values)) %>%
ggplot(aes(year, diff)) +
geom_point(aes(colour = continent)) +
geom_line(aes(group = continent, colour = continent)) +
ggtitle(data) +
ggsave(paste("plot1_", data), path = dir, device = "png")
})
map2(dataset, vals, function(data, values) {
get(data) %>%
filter(country %in% c("Denmark", "United States")) %>%
ggplot(aes_string("year", values)) +
geom_point(aes(colour = continent)) +
geom_line(aes(group = continent, colour = continent)) +
ggtitle(data) +
ggsave(paste("plot2_", data), path = dir, device = "png")
})
tidy_datasets <-
map2(dataset, vals, function(data, values) {
get(data) %>%
group_by(region, year) %>%
dplyr_mean("values", as.name(values)) %>%
spread(year, values)
}) %>%
setNames(c("tidy_pv_data", "tidy_quant_data"))
list_pisa <-
map(tidy_datasets, function(data) {
map(seq_len(nrow(data)), function(data_rows) {
as.numeric(data[data_rows, -1])
})
}) %>%
map(function(list_data) {
names(list_data) <- tidy_datasets[[1]]$region
list_data
})
list_pisa %>%
map(function(data) {
map(data, function(time) mean(diff(time) > 0, na.rm = T)) %>%
Filter(function(inequality) !is.nan(inequality), .) %>%
enframe() %>%
unnest(value) %>%
ggplot(aes(reorder(name, value), value)) +
geom_point() +
scale_y_continuous(limits = c(0, 1)) +
coord_flip()
})
map2(dataset, vals, function(data, values) {
get(data) %>%
ggplot(aes_string("year", values, colour = "country")) +
geom_smooth(aes(group = region), method = "glm") +
facet_wrap(~ region) +
scale_colour_discrete(guide = F) +
ggtitle(data) +
ggsave(paste("plot3_", data), path = dir, device = "png")
})
map2(dataset, vals, function(data, values) {
get(data) %>%
ggplot(aes_string("year", values, colour = "country")) +
geom_point(aes(colour = country), size = 0.6) +
geom_line(aes(group = country)) +
facet_wrap(~ region) +
scale_colour_discrete(guide = F) +
ggtitle(data) +
ggsave(paste("plot4_", data), path = dir, device = "png")
})
map2(dataset, vals, function(data, values) {
get(data) %>%
filter(!is.na(continent)) %>%
ggplot(aes_string("year", values)) +
geom_smooth(aes(group = country), method = "glm") +
facet_wrap(~ country) +
ggtitle(data) +
ggsave(paste("plot5_", data), path = dir, device = "png")
})
dataset <- c("pisa_pv_differenced", "pisa_quant_differenced", "pisa_quant_differenced_eighty")
filter_vars <- c("high_edu", rep("Percentiles", 2))
vals <- c("Mean", rep("Score", 2))
dir <- normalizePath("./Google Drive/PhD project/PISA/plots/")
ls()
pisa_quant_differenced_eighty
pisa_quant_differenced
dataset <- c("pisa_pv_differenced", "pisa_quant_differenced", "pisa_quant_differenced_eighty")
filter_vars <- c("high_edu", rep("Percentiles", 2))
vals <- c("Mean", rep("Score", 2))
getwd()
dir <- "/Users/cimentadaj/Google Drive/PhD project/PISA/plots/"
dir.exists(dir)
dataset <- c("pisa_pv_differenced", "pisa_quant_differenced", "pisa_quant_differenced_eighty")
filter_vars <- c("high_edu", rep("Percentiles", 2))
vals <- c("Mean", rep("Score", 2))
dir <- "/Users/cimentadaj/Google Drive/PhD project/PISA/plots/"
map2(dataset, vals, function(data, value) {
get(data) %>%
filter(continent == "Europe") %>%
ggplot(aes_string("year", value)) +
geom_smooth(aes(group = country, colour = country), method = "lm",
se = F) +
ggtitle(data) +
ggsave(paste("plot0_", data), path = dir, device = "png")
})
# Function to do non-standard filtering. In case needed
# dplyr_filter <- function(df, name, what_filter) {
#   df %>%
#     filter_(.dots = lazyeval::interp(~ y == x, y = as.name(name), x = what_filter))
# }
dplyr_mean <- function(df, new_name, x) {
df %>%
summarise_(.dots = setNames(list(lazyeval::interp(~ mean(x, na.rm = T), x  = x)), new_name))
}
# Lower variance for each year
# Lower difference in general
# Estimate by excluding the outliers
# in the model.
map(seq_along(dataset), function(index) {
summarise_dots <- setNames(list(lazyeval::interp(~ sd(x, na.rm = T), x  = as.name(vals[index])),
lazyeval::interp(~ mean(x, na.rm = T), x  = as.name(vals[index]))),
c("var", "mean_diff"))
get(dataset[index]) %>%
group_by(year) %>%
summarise_(.dots = summarise_dots)
}) %>%
setNames(dataset)
# Convergence of continents
map2(dataset, vals, function(data, values) {
get(data) %>%
group_by(year, continent) %>%
dplyr_mean("diff", as.name(values)) %>%
ggplot(aes(year, diff)) +
geom_point(aes(colour = continent)) +
geom_line(aes(group = continent, colour = continent)) +
ggtitle(data) +
ggsave(paste("plot1_", data), path = dir, device = "png")
})
map2(dataset, vals, function(data, values) {
get(data) %>%
filter(country %in% c("Denmark", "United States")) %>%
ggplot(aes_string("year", values)) +
geom_point(aes(colour = continent)) +
geom_line(aes(group = continent, colour = continent)) +
ggtitle(data) +
ggsave(paste("plot2_", data), path = dir, device = "png")
})
tidy_datasets <-
map2(dataset, vals, function(data, values) {
get(data) %>%
group_by(region, year) %>%
dplyr_mean("values", as.name(values)) %>%
spread(year, values)
}) %>%
setNames(c("tidy_pv_data", "tidy_quant_data"))
list_pisa <-
map(tidy_datasets, function(data) {
map(seq_len(nrow(data)), function(data_rows) {
as.numeric(data[data_rows, -1])
})
}) %>%
map(function(list_data) {
names(list_data) <- tidy_datasets[[1]]$region
list_data
})
list_pisa %>%
map(function(data) {
map(data, function(time) mean(diff(time) > 0, na.rm = T)) %>%
Filter(function(inequality) !is.nan(inequality), .) %>%
enframe() %>%
unnest(value) %>%
ggplot(aes(reorder(name, value), value)) +
geom_point() +
scale_y_continuous(limits = c(0, 1)) +
coord_flip()
})
map2(dataset, vals, function(data, values) {
get(data) %>%
ggplot(aes_string("year", values, colour = "country")) +
geom_smooth(aes(group = region), method = "glm") +
facet_wrap(~ region) +
scale_colour_discrete(guide = F) +
ggtitle(data) +
ggsave(paste("plot3_", data), path = dir, device = "png")
})
map2(dataset, vals, function(data, values) {
get(data) %>%
ggplot(aes_string("year", values, colour = "country")) +
geom_point(aes(colour = country), size = 0.6) +
geom_line(aes(group = country)) +
facet_wrap(~ region) +
scale_colour_discrete(guide = F) +
ggtitle(data) +
ggsave(paste("plot4_", data), path = dir, device = "png")
})
map2(dataset, vals, function(data, values) {
get(data) %>%
filter(!is.na(continent)) %>%
ggplot(aes_string("year", values)) +
geom_smooth(aes(group = country), method = "glm") +
facet_wrap(~ country) +
ggtitle(data) +
ggsave(paste("plot5_", data), path = dir, device = "png")
})
#TODO: You could cluster the patterns of countries
